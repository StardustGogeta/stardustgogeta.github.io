<!DOCTYPE html>
<head>
    <title>CMSC250 Handbook</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" integrity="sha384-Um5gpz1odJg5Z4HAmzPtgZKdTBHZdw8S29IecapCSB31ligYPhHQZMIlWLYQGVoc" crossorigin="anonymous">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.js" integrity="sha384-YNHdsYkH6gMx9y3mRkmcJ2mFUjTd0qNQQvY9VYZgQd7DcN7env35GzlmFaZ23JGp" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/contrib/auto-render.min.js" integrity="sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl" crossorigin="anonymous"></script>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.1/dist/css/bootstrap.min.css" rel="stylesheet"
		integrity="sha384-+0n0xVW2eSR5OomGNYDnhzAbDsOXxcvSN1TPprVMTNDbiYZCxYbOOl7+AMvyTG2x" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.1/dist/js/bootstrap.bundle.min.js"
        integrity="sha384-gtEjrD/SeCtmISkJkNUaaKMoLD0//ElJ19smozuHV6z3Iehds+3Ulb9Bn9Plx0x4" crossorigin="anonymous" defer></script>
    <script src="../math.js" defer></script>
</head>
<br>
<div class='container'>
<h1>Probability and Combinatorics</h1>
If you've ever played a game of Texas Hold'em poker, you're familiar with the fact that certain hands are worth more than others. 
For example, <a href="https://www.cardplayer.com/rules-of-poker/hand-rankings">a flush is better than a straight, and a full house is better than either</a>. Why is this the case?<br>
You may have some intuitive understanding that the more rare a hand is, the higher its rank. Using the ideas discussed here, we will be able to prove this relationship holds.
<hr>

<h2>Addition and Multiplication Principles</h2>
Combinatorics is all about <i>counting</i>. In particular, we often count the number of ways in which we can perform an action or a set of actions.
The <a href="https://brilliant.org/wiki/rule-of-sum-and-rule-of-product-problem-solving/">addition and multiplication principles</a> help with this analysis.
<ul>
    <li>The <b>addition principle</b> (or "rule of sum") states that given two different actions where there are `x` choices for the first one
        and `y` choices for the second, there are `x+y` ways of doing either, assuming it is not possible to do both actions simultaneously.</li>
    <li>The <b>multiplication principle</b> (or "rule of product") states that given two different actions where there are `x` choices for the first one
        and `y` choices for the second, there are `xy` ways of performing both actions together (in any order).</li>
</ul>

<card class="card my-3">
    <h5 class="card-header">Example</h5>
    <div class="card-body">
        Consider a person ordering a single meal at an Italian restaurant. The menu has only two items: specialty pizza and salad.
        The salad consists only of lettuce and dressing, where there are three choices of lettuce and two types of dressing.
        Meanwhile, the pizza comes in one of four different pre-made varieties. How many total meal options are there?
        <hr>
        We have two choices, pizza or salad, so we count the number of possible salads and the number of possible pizzas and add them together by the addition principle.
        The pizza clearly has only four options, as was given. However, counting the number of salad choices we have requires the multiplication rule.
        With `3` choices of lettuce and `2` choices of dressing, we have `2\times3=6` ways of picking one of each to form a salad.
        Thus, we obtain a final answer of `4+6=10` total possible meal selections.
    </div>
</card>

<h2>Combinations and Permutations</h2>
Two fundamental concepts in the field of combinatorics are those of <b>combinations</b> and <b>permutations</b>.<br>
A permutation is an ordering of some collection of elements.
<!--<sup><a tabindex="0" role="button" data-bs-toggle="popover" data-bs-trigger="hover" data-bs-content="Some sources make the distinction that the permutation is not the collection itself but simply the ordering. This makes no practical difference.">[1]</a></sup>-->
The number of possible permutations of a set of `n` distinct elements is simply given by `n!`, where `!` denotes the factorial function.
<card class="card my-3">
    <h5 class="card-header">Derivation</h5>
    <div class="card-body">
        Suppose we have a set of `n` distinct elements. We want to create one permutation of this set.<br>
        We begin by picking the first element of the permutation. There are `n` elements to choose from, so there are `n` ways of doing this.
        Then, we select the second element of the permutation. There are now only `n-1` elements remaining, so there are `n-1` ways of doing this.
        We repeat until we have exhausted all elements of the original set, leaving only one choice for the last element in the permutation.
        By the multiplication principle, there are `n\cdot(n-1)\cdots1=n!` ways of performing this entire task.<br>
        Every unique sequence of choices results in a new permutation (and every permutation can be constructed in this manner),
        so there are exactly `n!` possible permutations of the original set.
    </div>
</card>

An ordering of `k` elements from a set of `n` elements is called a `k`-permutation. The number of possible `k`-permutations from a set of size `n` is given by
$$P(n, k)={}_nP_k=\frac{n!}{(n-k)!}.$$

<card class="card my-3">
    <h5 class="card-header">Derivation</h5>
    <div class="card-body">
        Suppose we have a set of `n` distinct elements. We want to create a permutation of size `k` from this set.<br>
        We begin by picking the first element of the permutation. There are `n` elements to choose from, so there are `n` ways of doing this.
        Then, we select the second element of the permutation. There are now only `n-1` elements remaining, so there are `n-1` ways of doing this.
        We repeat for a total of `k` elements, leaving `n-k` elements unselected.
        By the multiplication principle, there are `n\cdot(n-1)\cdots(n-k+1)=n!/(n-k)!` ways of performing this entire task.<br><br>
        Alternatively, we can first notice that there are `n!` permutations of all elements in the original set. By extracting the first `k` elements of
        any given permutation, we construct a `k`-permutation as desired. However, there are `n-k` elements not selected, and the `k`-permutation is repeated
        once for each of their `(n-k)!` possible arrangements. Dividing out the number of repetitions yields `n!/(n-k)!` as before.
    </div>
</card>

A combination is simply a set of elements without respect to order. For instance, the set `\{1, 5, 7\}` is a combination of three odd numbers.
This is <i>exactly the same</i> as the combinations `\{5, 7, 1\}`, `\{1, 7, 5\}`, etc., since order does not matter.<br>

The number of possible combinations of `k` elements from a set of size `n` is given by
$$C(n, k)={}_nC_k=\binom{n}{k}=\frac{n!}{k!(n-k)!}.$$

<card class="card my-3">
    <h5 class="card-header">Derivation</h5>
    <div class="card-body">
        Suppose we have a set of `n` distinct elements. We want to create a combination of size `k` from this set.<br>
        Note that from any combination of `k` elements, we can rearrange to form `k!` different `k`-permutations which correspond to it.
        Since we know that there are `P(n,k)=n!/(n-k)!` total `k`-permutations, there must be `P(n,k)/k!` total `k`-combinations, or
        $$\frac{n!}{k!(n-k)!}.$$
    </div>
</card>

<!-- Pascal's triangle, common combinatorial identities like choose 1, choose 0, Pascal identity -->

<h2>Preliminary Probability Definitions</h2>
There are a few ideas we need to define immediately. A lot of this may be familiar or intuitive, but it is still important to discuss.
A good source of information can be found <a href="https://www.math.tamu.edu/~Janice.Epstein/141/review/WIR10_Prob_1.pdf">here</a>, summarized below.
Other resources include <a href="https://www.statisticshowto.com/complementary-events/">Statistics How To</a> and <a href="https://mathworld.wolfram.com/Experiment.html">Wolfram MathWorld</a>,
though the latter can be fairly technical.
<ul>
    <li>An <b>experiment</b> is an activity with an observable result. (ex. Rolling a die)</li>
    <li>An <b>outcome</b> is a possible result of an experiment. (ex. Rolling a 5)</li>
    <li>The <b>sample space</b> is the set of all possible outcomes of an experiment. (Rolling a 1, 2, 3, 4, 5, or 6)</li>
    <li>An <b>event</b> is a subset of the sample space. (Rolling a 1, 3, or 5)</li>
    <ul>
        <li>An event can include some, none, or all of the events in the sample space.</li>
    </ul>
    <li>The <b>probability</b> of an event is the chance that it occurs.</li>
    <ul>
        <li>If all outcomes in a sample space have the same probability, then the probability of an event `E` occurring is simply
            the ratio of the number of outcomes in `E` to the total number of outcomes in the sample space.</li>
    </ul>
    <li>Two events are <b>disjoint / mutually exclusive</b> if they share no outcomes.</li>
    <ul>
        <li>Alternatively, we might say that the intersection of the two events is empty.</li>
    </ul>
    <li>Two events are <b>complementary</b> if they are disjoint and their union is the sample space (so exactly one must occur).</li>
    <ul>
        <li>If the first event is `A`, then the other is the <b>complement</b> of `A`, often denoted `A^c`.</li>
    </ul>
    <li>Two events `A` and `B` are <b>independent</b> if the probability of `A` does not depend on whether `B` occurs, and vice versa.</li>
    <ul>
        <li>If two events are not independent, then they are said to be <b>dependent</b>.</li>
    </ul>
</ul>
Several of these concepts involve basic set theory like union and intersection, so be sure to understand the meanings of those terms first.

<!-- Link to union / intersection, or discuss here via Venn diagram -->

<br><br>

<h2>Probability Axioms</h2>
There are <a href="https://www.probabilitycourse.com/chapter1/1_3_2_probability.php">three axioms</a> that form the foundation of probability theory, listed below.
<ol>
    <li>For any event `E`, we have `P(E)\ge0`.</li>
    <li>For a sample space `S`, we have `P(S)=1`.</li>
    <li>For <i>disjoint</i> events `E_1` through `E_n`, we have `P(E_1\cup E_2\cup\cdots\cup E_n)=P(E_1)+P(E_2)+\cdots+P(E_n)`.</li>
</ol>
These facts should be fairly intuitive. For the first one, we know that nothing should ever have a negative chance of occurring.
For the second, it is clear by definition that if we take the probability that an experiment's outcome is in the entire sample space, we will find this chance to be 100%.
The third should also be fairly obvious. For example, when rolling a fair die, if the chance of rolling a 1 is `1/6` and the chance of rolling a 2 or 3 is `1/3`,
then the chance of rolling a 1, 2, or 3 is `1/6+1/3=1/2`.
<br><br>
There are many important results that can be derived from these axioms, some of which are given below.
Proofs are available on <a href="https://en.wikipedia.org/wiki/Probability_axioms#Consequences">the associated Wikipedia page</a>.
<ul>
    <li>For events `A` and `B`, if `A\subseteq B`, then `P(A)\le P(B)`.</li>
    <li>The probability of the empty event `\emptyset` is `P(\emptyset)=0`.</li>
    <ul>
        <li>Note that it is still possible for a nonempty event to have zero probability, as well.</li>
    </ul>
    <li>For any event `A`, the probability of its complement is `P(A^c)=1-P(A)`.</li>
    <li>For any event `A`, its probability must satisfy `0\le P(A)\le1`.</li>
</ul>

One of the most important results is known as the <b>inclusion-exclusion principle</b>, which generalizes the third axiom to non-disjoint events.
Namely, we see that $$P(A\cup B)=P(A)+P(B)-P(A\cap B)$$ for any two events `A` and `B`. In essence, we remove the intersection because it is erroneously double-counted otherwise.
When we extend to the union of three or more events, the formulas become far more complicated.
$$\begin{align*}P(A\cup B\cup C)&=P(A)+P(B)+P(C)\\&-P(A\cap B)-P(B\cap C)-P(A\cap C)\\&+P(A\cap B\cap C)\end{align*}$$
$$\begin{align*}P(A\cup B\cup C\cup D)&=P(A)+P(B)+P(C)+P(D)\\
&-P(A\cap B)-P(A\cap C)-P(A\cap D)-P(B\cap C)-P(B\cap D)-P(C\cap D)\\
&+P(A\cap B\cap C)+P(A\cap B\cap D)+P(A\cap C\cap D)+P(B\cap C\cap D)\\
&-P(A\cap B\cap C\cap D)
\end{align*}$$

We proceed as before, adding the individual probabilities and then removing the double-counted pairwise intersections. However, this process removes
the three-way intersections too many times, so we need to add those back. If there are more than three events, then this will result in over-counting of
the four-way intersections, and we must remove one copy of each of those.<br><br>

Fortunately for us, <a href="https://proofwiki.org/wiki/Inclusion-Exclusion_Principle">it can be proven</a> that this pattern holds in general.
When applying the formula, simply be careful to include all required terms and to have the correct sign on each.
The number of terms can be easily checked - the number of `x`-way intersection terms from a set of `y` events is simply given by `\binom yx`.
Additionally, we see that the total number of terms for a set of `y` events should be `\sum_{i=1}^y\binom yi=2^y-1`.<br><br>

It should be noted that the inclusion-exclusion principle applies equivalently to set cardinality in place of probability since both are
<a href="https://proofwiki.org/wiki/Definition:Additive_Function_(Measure_Theory)">additive functions</a>
(i.e., the probabilities and cardinalities of disjoint unions are the sums of the components).

<br><br>

<h2>Conditional Probability and Bayes' Theorem</h2>
A common question to ask is "what is the chance of event `B` occurring given that event `A` occurs?" Questions like these fall into the realm of <b>conditional probability</b>.
We denote the probability of event `B` given event `A` as `P(B\mid A)`, with a vertical bar in-between. This quantity is defined as follows:
$$P(B\mid A)\overset{\text{def}}{=}\frac{P(A\cap B)}{P(A)}.$$

For example, consider rolling a fair six-sided die. Let event `A` be rolling an odd number, and let `B` be rolling a number less than 4.
It is trivial to find that `P(A)=1/2` and `P(A\cap B)=1/3`, and so we find `P(B\mid A)=(1/3)/(1/2)=2/3` as the chance of rolling less than 4 given that an odd number is rolled.
This makes senseâ€”it is either a 1, 3, or 5 with uniform probability, and exactly two of these three options are less than 4.<br><br>

<b>Bayes' theorem</b> (or "law," or "rule") takes this definition and expands it a bit. Since `P(A\cap B)=P(B\cap A)` (by commutativity of set intersection), we can write
$$P(A\cap B)=P(A)\cdot P(B\mid A)=P(B)\cdot P(A\mid B).$$

Then, we can simply rearrange to obtain that
$$P(A\mid B)=P(B\mid A)\left(\frac{P(A)}{P(B)}\right).$$

Finally since `P(B)=P(B\cap(A\cup A^c))=P((A\cap B) \cup (A^c\cap B))=P(A\cap B)+P(A^c\cap B)=P(A)\cdot P(B\mid A)+P(A^c)\cdot P(B\mid A^c)`, we can rewrite the fraction as
$$P(A\mid B)=\frac{P(A)\cdot P(B\mid A)}{P(A)\cdot P(B\mid A)+P(A^c)\cdot P(B\mid A^c)}.$$

Note how the numerator term appears in the denominator as well. Note also that `A` and `A^c` are not particularly special; we simply need a set of mutually exclusive
and collectively exhaustive events, and each one will contribute a separate term to the denominator.

<card class="card my-3">
    <h5 class="card-header">Example</h5>
    <div class="card-body">
        Consider an engineer ordering parts for his or her latest project. The engineer orders some gizmos from each of three companies: Advanced Applications (A), Dynamic Dynamos (D), and Mechanical Machines (M).
        One half of all gizmos are ordered from A, one third are from D, and the remaining gizmos are ordered from M.
        Unfortunately, none of these companies have perfect assembly lines, and each will occasionally produce defective parts.
        A randomly selected gizmo produced by A has a `1/100` chance of being defective, whereas the chances of gizmos by D or M being defective are `1/200` and `1/50`, respectively.
        If a gizmo is randomly selected from the set of all gizmos ordered and it is found to be defective, what are the odds it was made by Dynamic Dynamos?
        <hr>
        From the problem statement, we know that `P(A)=1/2`, `P(D)=1/3`, and `P(M)=1/6`.
        Additionally, `P(\text{Defect}\mid A)=1/100`, `P(\text{Defect}\mid D)=1/200`, and `P(\text{Defect}\mid M)=1/50`.
        Applying Bayes' theorem yields
        $$\begin{align*}
        P(D\mid\text{Defect})&=\frac{P(\text{Defect}\cap D)}{P(\text{Defect})}\\
        &=\frac{P(\text{Defect}\cap D)}{P(\text{Defect}\cap A)+P(\text{Defect}\cap D)+P(\text{Defect}\cap M)}\\
        &=\frac{P(\text{Defect}\mid D)\cdot P(D)}{P(\text{Defect}\mid A)\cdot P(A) + P(\text{Defect}\mid D)\cdot P(D) + P(\text{Defect}\mid M)\cdot P(M)}\\
        &=\frac{1/200\cdot 1/3}{1/100\cdot 1/2 + 1/200\cdot 1/3 + 1/50\cdot 1/6}\\
        &=\frac{1/600}{3/600 + 1/600 + 2/600}\\
        P(D\mid\text{Defect})&=\frac16.
        \end{align*}$$
        Thus, we find that the probability that a defective gizmo selected at random originated from Dynamic Dynamos is `1/6`.
    </div>
</card>

A more visual way of representing conditional probability is with <b>probability trees</b>.
A <a href="https://www.mathsisfun.com/data/probability-tree-diagrams.html">probability tree</a> is a tree diagram read from left to right where
nodes represent experiments and branches represent disjoint outcomes/events that might occur, each labeled with their respective probabilities.
In order to find the probability of a certain leaf, simply multiply the conditional probabilities along the edges leading from the root to that leaf.
Then, to obtain the probability of some set of leaves, find their individual probabilities and add them together.
(To verify that a tree diagram has been correctly constructed, the sum of all leaf probabilities should always equal one.)
<br><br>
Tree diagrams can be very helpful in certain situations involving dependent events and conditional probability, but their usefulness is limited
by how rapidly they grow in size. The number of leaves in such a tree grows exponentially with height, and this can very quickly become unwieldy.
<br><br>

<h2>Independence of Events</h2>
Colloquially, two events are independent if they do not impact one another's odds.<br>
Formally, we say that events `A` and `B` are independent if and only if the following condition holds true:
$$P(A\cap B)=P(A)\cdot P(B).$$

If `A` and `B` both have nonzero probability, we can use the definition of conditional probability to obtain these two conditions, each equivalent to the one above:
$$P(A\mid B)=P(A),$$
$$P(B\mid A)=P(B).$$

Notice that if an event does indeed have zero probability, then it is automatically independent of all other events.<br>
Furthermore, if two events of nonzero probability are disjoint, then `P(A\cap B)=0` and they cannot be independent.<br>
Finally, it is possible to find a couple more equivalent conditions (under the assumption `0 < P(A), P(B) < 1`), though these are far less common:
$$P(A\mid B)=P(A\mid B^c),$$
$$P(B\mid A)=P(B\mid A^c).$$

This result is not hard to prove and aligns with our intuition about the notion of event independence.
<br><br>

<h2>Application: Card Games</h2>
One of the best examples of probability in action is playing card games. Take, for example, the game of Texas Hold'em poker.
If you're not familiar with the game, you can read the rules <a href="https://bicyclecards.com/how-to-play/texas-holdem-poker/">here</a>.
In poker, <i>hands</i> consist of five cards each, taken from a standard deck of fifty-two. Each card has a <i>suit</i> (hearts, diamonds, spades, clubs)
and a <i>rank</i> (in ascending order, 2, 3, 4, 5, 6, 7, 8, 9, 10, jack, queen, king, ace). Depending on the exact suit and rank composition of the cards
in one's hand, it will be considered better or worse than (or in rare cases, equal to) another hand. For more information on hand evaluation and ranking,
see <a href="https://www.cardplayer.com/rules-of-poker/hand-rankings">here</a> and <a href="https://automaticpoker.com/poker-basics/what-happens-if-you-have-the-same-hand-in-poker/">here</a>.
<br><br>
Why are certain hands worth more than others? It is because these hands are provably less common!
We can show this using the probability techniques developed above.
Here's the ordered list of poker hands:
<ol>
    <li>Royal Flush</li>
    <li>Straight Flush</li>
    <li>Four of a Kind</li>
    <li>Full House</li>
    <li>Flush</li>
    <li>Straight</li>
    <li>Three of a Kind</li>
    <li>Two Pair</li>
    <li>One Pair</li>
    <li>No Pair / High Card</li>
</ol>
Let's derive the probabilities of each of these hands occurring when five cards are dealt at random from a standard deck.
<br><br>
A <i>royal flush</i> occurs when we have the ten, jack, queen, king, and ace of a given suit. The ranks are prescribed by definition, but we have four choices for the
suit, so there are four unique royal flushes that are possible. Since there are `\binom{52}{5}` possible hands in total, each with the same chance of occurring,
we obtain a probability of `4/\binom{52}{5}\approx0.000154\%` for dealing a royal flush.
<br><br>
A <i>straight flush</i> occurs when we have five cards in a row of the same suit, excluding a royal flush.
Notice that each straight flush can be uniquely identified by its lowest card.
(There is only one possibility for a straight flush that starts with the Five of Hearts, for example.) Now, how many possibilities are there for this lowest card?
There have to be four cards after it in sequence, meaning that 9-10-J-Q-K is the highest we can go (since we do not count royal flushes),
and A-2-3-4-5 is the lowest we can go. Since the lowest card ranges from an ace to a nine in any of the four suits, we have exactly 36 possibilities, and as a result, we know there are 36 unique straight flushes.
We proceed to obtain a probability of `36/\binom{52}{5}\approx0.00139\%` for being dealt a straight flush.
<br><br>
A <i>four of a kind</i> is when we have all four cards of a given rank (along with any other card as the fifth).
We have 13 ways to pick the rank for which we have the four of a kind, followed by 48 ways to pick the remaining card.
Thus, the probability of a four of a kind is given by `13\cdot48/\binom{52}{5}\approx0.02401\%`.
<br><br>
A <i>full house</i> occurs if we have three cards of one rank (let's call it `A`) and two cards of another rank (let's call it `B`).
We have `P(13,2)=13\cdot12` ways to choose ranks `A` and `B`. Next, we pick the suits.
There are three suits for rank `A`, so we have `\binom43=4` ways of picking them.
Likewise, we have `\binom42=6` ways of picking the two suits for the cards of rank `B`.
Consequently, we find a probability of `13\cdot12\cdot4\cdot6/\binom{52}{5}\approx0.1441\%`.
<br><br>
A <i>flush</i> occurs if we have five cards of the same suit.
We have 4 ways to pick the suit and `\binom{13}5` ways to pick five ranks within that suit.
However, we have to guarantee that this is not a straight or royal flush as well.
There are ten total possibilities for a straight/royal flush within a given suit, so we simply subtract this from our count.
In the end, we have a probability of `4\cdot\left(\binom{13}5-10\right)/\binom{52}{5}\approx0.1965\%`.
<br><br>
A <i>straight</i> occurs whenever we have five cards in a row (and do not also have a royal straight or straight flush).
There are 10 ways to pick the ranks, but unlike straight flushes, we now have 4 choices for each card's suit.
This leads to a total of `10\cdot4^5` possibilities, before subtracting the 40 royal and straight flushes.
a probability of `\left(10\cdot4^5-40\right)/\binom{52}{5}\approx0.3925\%`.
<br><br>
A <i>three of a kind</i> occurs whenever we have three cards of a single rank (which we will call `A`) and two cards of different ranks (`B` and `C`).
There are 13 ranks to choose from for `A`. Then, we have `\binom{12}2` ways to pick ranks `B` and `C` afterwards.
(Note that unlike the full house before, there is a symmetry here.
Ranks `B` and `C` each contribute the same number of cards, one, so the order in which they are chosen does not matter.
Since `A` is associated with a different number of cards, namely three, it has to be chosen separately from `B` and `C`.)
There are `\binom43=4` ways to pick the suits for rank `A` and `4^2` ways to pick the suits for `B` and `C`.
This yields a probability of `13\cdot\binom{12}2\cdot4^3/\binom{52}{5}\approx2.1128\%`.
<br><br>
A <i>two pair</i> happens whenever we have two cards of one rank (`A`), two cards of another rank (`B`), and one card of a third rank (`C`).
By the same symmetry argument as before, we pick ranks for `A` and `B` together, and we have `\binom{13}2` ways of doing so.
There are 11 choices left for rank `C` afterwards.
There are `\binom42=6` ways each to pick the suits for ranks `A` and `B`, and there are 4 ways to pick the suit for `C`.
This yields a probability of `\binom{13}2\cdot11\cdot6^2\cdot4/\binom{52}{5}\approx4.7539\%`.
<br><br>
A <i>one pair</i> happens whenever we have two cards of one rank (`A`) and one card each from three other ranks (`B`, `C`, and `D`).
There are 13 choices for rank `A`, after which there are `\binom{12}3` choices for the other ranks.
There are `\binom42=6` ways to pick the suits for rank `A` and there are 4 ways to pick the suits for each of the other three cards.
This generates a probability of `13\cdot\binom{12}3\cdot6\cdot4^3/\binom{52}{5}\approx42.2569\%`.
<br><br>
Finally, it comes down to the <i>high card</i> if and only if none of the other types of hands occur.
Adding the probabilities above gives a total chance of `49.8823\%`, so the chance of none of those is about `50.1177\%`.
Alternatively, we can directly calculate the odds. There are `\binom{13}5-10` ways to pick the five distinct ranks (and not form a straight),
and there are `4^5-4` ways to pick the five suits (while not giving a flush).
Together, we get a probability of `\left(\binom{13}5-10\right)\left(4^5-4\right)/\binom{52}{5}\approx50.1177\%`, as expected.
<br><br>
All in all, we see that the <a href="https://en.wikipedia.org/wiki/Poker_probability">probabilities of the poker hands</a> are ordered exactly as we predicted.
Rarer types of hands are worth more, without exception.
<br><br>
How about some non-poker cards questions?

<card class="card my-3">
    <h5 class="card-header">Example</h5>
    <div class="card-body">
        Suppose I perfectly shuffle a standard deck (so that any permutation of the cards is equally likely).
        What are the odds that the top half of the deck contains the same set of cards before and after shuffling?
        <hr>
        This is a simple counting problem.
        If the top and bottom halves of the deck remain the same before and after shuffling, then that means there are `26!` ways to rearrange each half,
        so there are `(26!)^2` permutations of the deck that satisfy the condition.
        Meanwhile, there are `52!` total distinct permutations of the deck that are possible.
        If each rearrangement is equally likely, the probability that the condition is satisfied is `(26!)^2/52!`.
    </div>
</card>

<card class="card my-3">
    <h5 class="card-header">Example</h5>
    <div class="card-body">
        Suppose I perfectly shuffle a standard deck and deal out a game of Klondike solitaire as shown. What is the probability that
        all four aces will be face-up at the very start of the game, before any moves are made?
        <center style="overflow-y:hidden; height: 240px">
            <img style="margin-top: -25px;" src="https://pbs.twimg.com/media/E1wyRfCXsAUXSYA.jpg" height="320"/>
        </center>
        <hr>
        This is just another routine application of the probability principles we have reviewed.
        There are seven cards face-up at the beginning, of which four are aces and three are non-aces.
        There are `\binom{48}3` ways to select the three non-aces from the deck, and there are `7!` ways to permute these seven cards together.
        Then, there are `45!` ways to permute the cards that begin face-down or in the draw pile.
        On the other hand, we have `52!` total rearrangements of the deck that are possible.
        Therefore, the probability is `\frac{\binom{48}3\cdot7!\cdot45!}{52!}=\frac1{7735}`.
        <br><br>
        Alternatively, there are `\binom74` ways to pick which of the seven face-up positions will be occupied by aces,
        `P(4,4)=4!` ways to arrange the aces, and `P(48,3)=48\cdot47\cdot46` ways to select the non-aces in order.
        Then, since there are `P(52,7)` ways to pick the face-up cards in order, we get a probability of
        `\frac{\binom74\cdot4!\cdot48\cdot47\cdot46}{P(52,7)}=\frac1{7735}` as before.
    </div>
</card>

<card class="card my-3">
    <h5 class="card-header">Example</h5>
    <div class="card-body">
        Suppose I deal out a game of Klondike solitaire as in the previous example.
        However, I can't make any moves with what I see, so I reshuffle and lay out the cards again.
        What is the probability that the exact same set of seven cards is face-up (ignoring order)?
        <hr>
        There are `7!` ways to permute the seven face-up cards and `45!` ways to permute the rest.
        Since there are `52!` possible (equally likely) orderings of the cards in total,
        this yields a probability of `\frac{7!\cdot45!}{52!}=\binom{52}{7}^{-1}=\frac1{133,784,560}`.
        <br><br>
        Alternatively, there are `\binom{52}7` ways to pick the seven face-up cards from the deck while ignoring order.
        There is only one of these that will match the face-up set from before the reshuffle, so the chance that that
        will occue is `\binom{52}{7}^{-1}` as above.
    </div>
</card>

<h2>Application: Disease Testing</h2>
Another common application of probability (and Bayes' theorem, in particular) is disease testing.
<br><br>
When there is <a href="https://en.wikipedia.org/wiki/COVID-19_pandemic">an illness spreading throughout the population</a> that
<a href="https://en.wikipedia.org/wiki/Epidemiology_of_HIV/AIDS">may not present clear symptoms</a>,
it is immensely helpful to have a way to test whether an individual has the disease.
Unfortunately, these kinds of tests are not perfect. Sometimes, an infected individual will be marked disease-free, or vice versa.
To describe these events, here are some terms to know:
<ul>
    <li><b>True Positive</b>: Individual has the disease, test indicates they have the disease</li>
    <li><b>False Positive</b>: Individual does not have the disease, test indicates they have the disease</li>
    <li><b>True Negative</b>: Individual does not have the disease, test indicates they do not have the disease</li>
    <li><b>False Negative</b>: Individual has the disease, test indicates they do not have the disease</li>
</ul>
In short, for each of the above, "true" / "false" tells whether the test result is correct, and "positive" / "negative" simply tells the result of the test.
<br><br>
Although we don't know exactly which tests have incorrect results, we can find the proportion of tests
that will tend to be correct or incorrect under varying circumstances.
That leads us to some more important terms to know:
<ul>
    <li><b>Sensitivity / True Positive Rate (TPR)</b>: The proportion of infected individuals correctly marked as having the disease</li>
    <li><b>False Positive Rate (FPR)</b>: The proportion of uninfected individuals incorrectly marked as having the disease</li>
    <li><b>Specificity / True Negative Rate (TNR)</b>: The proportion of uninfected individuals correctly marked as not having the disease</li>
    <li><b>False Negative Rate (FNR)</b>: The proportion of infected individuals incorrectly marked as not having the disease</li>
</ul>
These are all characteristics of the test itself, independent of the number of individuals tested.
<br><br>
On the other hand, there are some terms that do depend on the population or the number of individuals tested.
<ul>
    <li><b>Prevalence</b>: The proportion of the general population that is infected with the disease</li>
    <li><b>Precision / Positive Predictive Value (PPV)</b>: The proportion of those marked as having the disease who are actually infected</li>
    <li><b>Negative Predictive Value (NPV)</b>: The proportion of those marked as not having the disease who are actually not infected</li>
    <li><b>False Discovery Rate (FDR)</b>: The proportion of those marked as having the disease who are actually not infected</li>
    <li><b>False Omission Rate (FOR)</b>: The proportion of those marked as not having the disease who are actually infected</li>
</ul>
Note that if `D+` and `D-` indicate disease-positive and disease-negative while `T+` and `T-` indicate positive and negative test results, respectively,
then TPR is `P(T+\mid D+)`, FPR is `P(T+\mid D-)`, TNR is `P(T-\mid D-)`, and FNR is `P(T-\mid D+)`. Meanwhile, prevalence is `P(D+)`,
PPV is `P(D+\mid T+)`, NPV is `P(D-\mid T-)`, FDR is `P(D-\mid T+)`, and FOR is `P(D+\mid T-)`.
<br><br>
Since a test returns either positive or negative in any case, we can see that `\text{TPR}+\text{FNR}=1` and `\text{FPR}+\text{TNR}=1`.
Additionally, since any individual either has the disease or does not, we have that `\text{PPV}+\text{FDR}=1` and `\text{NPV}+\text{FOR}=1`.
<br><br>
One incredibly useful tool for keeping track of the meanings of these terms is known as a <b>confusion matrix</b>.

<!-- Confusion matrix -->

<card class="card my-3">
    <h5 class="card-header">Example</h5>
    <div class="card-body">
        Suppose there is a disease going around, and scientists have devised a test to determine whether a given individual is infected.
        The test has a false-positive rate of 0.05 and a false-negative rate of 0.01. Only five percent of the general population has the disease.
        Given that a certain person receives a positive test result, what is the likelihood that they truly are infected?
        <hr>
        We will first individually calculate the probabilities of a true positive and a false positive when testing a random individual from the general population.
        <br><br>
        Since the FPR is 0.05 and the prevalence is 0.05, we see that the probability of a false positive is `P(T+\mid D-)\cdot(1-P(D+))=0.05\cdot0.95=0.0475`.
        Then, the FNR is 0.01 and the prevalence is 0.05, so we find the probability of a true positive is `(1-P(T-\mid D+))\cdot P(D+)=0.99\cdot0.05=0.0495`.
        Thus, the we find the answer to be `P(D+\mid T+)=\frac{P(T+\cap D+)}{P(T+)}=\frac{P(T+\cap D+)}{P(T+\cap D+)+P(T+\cap D-)}=\frac{0.0495}{0.0495+0.0475}\approx0.5103`, or `51.03\%`.
    </div>
</card>

<br><br>
